{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Problemas de Clasificación\n",
        "\n",
        "Ernesto Reynoso Lizárraga A01639915"
      ],
      "metadata": {
        "id": "rFw5iErg7KG2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "o7nTyQF_Yr9_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.feature_selection import SelectKBest, SequentialFeatureSelector,RFE, f_classif\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Problema 1"
      ],
      "metadata": {
        "id": "OF5khek3j-Xt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = np.loadtxt(\"/content/drive/MyDrive/Inteligencia Artificial/P1_3.txt\")"
      ],
      "metadata": {
        "id": "HcJ8CGo0Zc7S"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = df[:,2:]\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCJckZWLZtNk",
        "outputId": "39a81534-b37c-4a65-fda2-efd150e6537b"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.3925073 ,  0.67657019,  0.60180412, ...,  1.24975793,\n",
              "         1.03738802,  1.05531121],\n",
              "       [-1.31487611, -0.73287418,  0.41422541, ..., -0.61989557,\n",
              "        -1.05137325, -1.19338103],\n",
              "       [-1.09345032, -0.68931183,  0.07082691, ..., -0.29226011,\n",
              "        -0.2000579 ,  0.28090627],\n",
              "       ...,\n",
              "       [-0.72853565, -0.78422092,  0.02350863, ..., -0.00920863,\n",
              "         0.12140923,  0.39523656],\n",
              "       [ 1.77147543,  0.83735529,  0.18184615, ..., -0.45705499,\n",
              "        -1.52412392, -1.73872657],\n",
              "       [ 0.47996947, -0.54432989, -0.75249618, ..., -0.18374824,\n",
              "        -0.69901401, -1.41618733]])"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = df[:,0]\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilt_jLP5sZAg",
        "outputId": "c69af9a2-2a2e-4cd4-95ac-bdaf47cf9b85"
      },
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 1., ..., 2., 2., 2.])"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Determina si es necesario balancear los datos. En caso de que sea afirmativo, en todo este ejercicio tendrás que utilizar alguna estrategia para mitigar el problema de tener una muestra desbalanceada."
      ],
      "metadata": {
        "id": "_akWWidVj7EA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "realizando diferentes estrategias para balancear los datos y comparandolos con el modelo de datos desvalanceados, podemos concluir que no hace falta balancear los datos"
      ],
      "metadata": {
        "id": "IBy88F8OkDwS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Evalúa al menos 5 modelos de clasificación distintos utilizando validación cruzada, y determina cuál de ellos es el más efectivo."
      ],
      "metadata": {
        "id": "v7UzQKtTkYEq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kf = StratifiedKFold(n_splits=5, shuffle = True)\n",
        "clf = SVC(kernel = 'linear')\n",
        "cv_y_test = []\n",
        "cv_y_pred = []\n",
        "for train_index, test_index in kf.split(x, y):\n",
        "  # Training phase\n",
        "  x_train = x[train_index, :]\n",
        "  y_train = y[train_index]\n",
        "  clf.fit(x_train, y_train)\n",
        "  # Test phase\n",
        "  x_test = x[test_index, :]\n",
        "  y_test = y[test_index]\n",
        "  y_pred = clf.predict(x_test)\n",
        "  cv_y_test.append(y_test)\n",
        "  cv_y_pred.append(y_pred)\n",
        "\n",
        "print(classification_report(np.concatenate(cv_y_test), np.concatenate(cv_y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FjqFFo0nGQQ",
        "outputId": "24cc476c-0357-4818-a6cb-880f39bc52cd"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.73      0.66      0.69       298\n",
            "         2.0       0.93      0.95      0.94      1496\n",
            "\n",
            "    accuracy                           0.90      1794\n",
            "   macro avg       0.83      0.80      0.82      1794\n",
            "weighted avg       0.90      0.90      0.90      1794\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RBF SVM\n",
        "print('----- RBF-SVM -----')\n",
        "kf = StratifiedKFold(n_splits=5, shuffle = True)\n",
        "cv_y_test = []\n",
        "cv_y_pred = []\n",
        "for train_index, test_index in kf.split(x, y):\n",
        "  x_train = x[train_index, :]\n",
        "  y_train = y[train_index]\n",
        "  x_test = x[test_index, :]\n",
        "  y_test = y[test_index]\n",
        "\n",
        "  clf = SVC(kernel = 'rbf')\n",
        "  clf.fit(x_train, y_train)\n",
        "  y_pred = clf.predict(x_test)\n",
        "  cv_y_test.append(y_test)\n",
        "  cv_y_pred.append(y_pred)\n",
        "\n",
        "print(classification_report(np.concatenate(cv_y_test), np.concatenate(cv_y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roSunLaWrkCE",
        "outputId": "33d911df-2654-486d-fa49-72db15dc8e74"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- RBF-SVM -----\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.87      0.58      0.70       298\n",
            "         2.0       0.92      0.98      0.95      1496\n",
            "\n",
            "    accuracy                           0.92      1794\n",
            "   macro avg       0.90      0.78      0.83      1794\n",
            "weighted avg       0.91      0.92      0.91      1794\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN\n",
        "print('----- KNN -----')\n",
        "kf = StratifiedKFold(n_splits=5, shuffle = True)\n",
        "cv_y_test = []\n",
        "cv_y_pred = []\n",
        "for train_index, test_index in kf.split(x, y):\n",
        "  x_train = x[train_index, :]\n",
        "  y_train = y[train_index]\n",
        "  x_test = x[test_index, :]\n",
        "  y_test = y[test_index]\n",
        "\n",
        "  clf = KNeighborsClassifier(n_neighbors=3)\n",
        "  clf.fit(x_train, y_train)\n",
        "  y_pred = clf.predict(x_test)\n",
        "  cv_y_test.append(y_test)\n",
        "  cv_y_pred.append(y_pred)\n",
        "print(classification_report(np.concatenate(cv_y_test), np.concatenate(cv_y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiP5Q7xOuBx9",
        "outputId": "c27ff203-d5c8-4775-b2fb-34e3535df708"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- KNN -----\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.66      0.42      0.51       298\n",
            "         2.0       0.89      0.96      0.92      1496\n",
            "\n",
            "    accuracy                           0.87      1794\n",
            "   macro avg       0.78      0.69      0.72      1794\n",
            "weighted avg       0.85      0.87      0.86      1794\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision tree\n",
        "print('----- Decision tree -----')\n",
        "kf = StratifiedKFold(n_splits=5, shuffle = True)\n",
        "cv_y_test = []\n",
        "cv_y_pred = []\n",
        "for train_index, test_index in kf.split(x, y):\n",
        "  x_train = x[train_index, :]\n",
        "  y_train = y[train_index]\n",
        "  x_test = x[test_index, :]\n",
        "  y_test = y[test_index]\n",
        "  clf = DecisionTreeClassifier()\n",
        "  clf.fit(x_train, y_train)\n",
        "  y_pred = clf.predict(x_test)\n",
        "  cv_y_test.append(y_test)\n",
        "  cv_y_pred.append(y_pred)\n",
        "print(classification_report(np.concatenate(cv_y_test), np.concatenate(cv_y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjffHATSxaCD",
        "outputId": "2c3ccc55-4915-46d5-c99a-1edb36b4bbfb"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- Decision tree -----\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.46      0.45      0.45       298\n",
            "         2.0       0.89      0.89      0.89      1496\n",
            "\n",
            "    accuracy                           0.82      1794\n",
            "   macro avg       0.67      0.67      0.67      1794\n",
            "weighted avg       0.82      0.82      0.82      1794\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear Discriminant Analysis\n",
        "print('----- Linear Discriminant Analysis -----')\n",
        "kf = StratifiedKFold(n_splits=5, shuffle = True)\n",
        "cv_y_test = []\n",
        "cv_y_pred = []\n",
        "for train_index, test_index in kf.split(x, y):\n",
        "  x_train = x[train_index, :]\n",
        "  y_train = y[train_index]\n",
        "  x_test = x[test_index, :]\n",
        "  y_test = y[test_index]\n",
        "  clf = LinearDiscriminantAnalysis()\n",
        "  clf.fit(x_train, y_train)\n",
        "  y_pred = clf.predict(x_test)\n",
        "  cv_y_test.append(y_test)\n",
        "  cv_y_pred.append(y_pred)\n",
        "print(classification_report(np.concatenate(cv_y_test), np.concatenate(cv_y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENdQWdP1xQaT",
        "outputId": "5a9f60f0-f595-479d-83fb-2ffdfb80a188"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- Linear Discriminant Analysis -----\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.70      0.65      0.68       298\n",
            "         2.0       0.93      0.95      0.94      1496\n",
            "\n",
            "    accuracy                           0.90      1794\n",
            "   macro avg       0.82      0.80      0.81      1794\n",
            "weighted avg       0.89      0.90      0.90      1794\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparando los 5 modelos, podemos determinar que le mejor modelo para estos datos es el modelo de clasificación lineal."
      ],
      "metadata": {
        "id": "A6K9CIlpxrvP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementa desde cero el método de regresión logística, y evalúalo con el conjunto de datos"
      ],
      "metadata": {
        "id": "Yg1NLsEvx0Iy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient(X, y, beta):\n",
        "    xbeta = X @ beta\n",
        "    c0 = (y == 0)\n",
        "    c1 = (y == 1)\n",
        "\n",
        "    exp0 = np.exp(xbeta[c0])\n",
        "    l0 = (exp0 / (1 + exp0)) * X[c0, :].transpose()\n",
        "\n",
        "    exp1 = np.exp(xbeta[c1])\n",
        "    l1 = (exp1 / (1 + exp1)) * X[c1, :].transpose()\n",
        "\n",
        "    return l0.sum(axis=1) - l1.sum(axis=1)\n",
        "\n",
        "\n",
        "def fit_model(X, y, alpha=0.0005, max_iterations=100000):\n",
        "  npredictors = X.shape[1]\n",
        "  beta = 2 * np.random.rand(npredictors) - 1.0\n",
        "  it = 0\n",
        "\n",
        "  while (np.linalg.norm(gradient(X, y, beta)) > 1e-4) and (it < max_iterations):\n",
        "      beta = beta - alpha * gradient(X, y, beta)\n",
        "      it = it + 1\n",
        "\n",
        "  return beta\n",
        "\n",
        "def predict(X, beta):\n",
        "        xbeta = X @ beta\n",
        "        tmp = 1. / (1. + np.exp(-xbeta))\n",
        "        return (tmp > 0.5).astype(\"int32\")"
      ],
      "metadata": {
        "id": "yPZD8fAIx7JN"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Divide los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Normaliza las características utilizando StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "LF-FWtUlQMCT"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beta = fit_model(X_train, y_train, max_iterations=100)\n",
        "y_pred = predict(X_test, beta)\n",
        "accuracy = np.mean(y_test == y_pred)\n",
        "print('Precision:',accuracy * 100, '%')\n",
        "print(classification_report(y_test, y_pred, zero_division=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2JzvA9r1UTCX",
        "outputId": "c1873125-e110-4fd0-8958-4c3b79de593b"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 13.649025069637883 %\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.00      1.00      0.00         0\n",
            "         1.0       0.32      0.94      0.47        52\n",
            "         2.0       1.00      0.00      0.00       307\n",
            "\n",
            "    accuracy                           0.14       359\n",
            "   macro avg       0.44      0.65      0.16       359\n",
            "weighted avg       0.90      0.14      0.07       359\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Con alguno de los clasificadores que probaste en los pasos anteriores, determina el número óptimo de características utilizando un método tipo Filter."
      ],
      "metadata": {
        "id": "BS_BweEsjD1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find optimal number of features using cross-validation\n",
        "################################################################################\n",
        "print(\"----- Optimal selection of number of features -----\")\n",
        "n_feats = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
        "acc_nfeat = []\n",
        "for n_feat in n_feats:\n",
        "  print('---- n features =', n_feat)\n",
        "  acc_cv = []\n",
        "  kf = StratifiedKFold(n_splits=5, shuffle = True)\n",
        "  for train_index, test_index in kf.split(x, y):\n",
        "    # Training phase\n",
        "    x_train = x[train_index, :]\n",
        "    y_train = y[train_index]\n",
        "    clf_cv = SVC(kernel = 'linear')\n",
        "    fselection_cv = SelectKBest(f_classif, k = n_feat)\n",
        "    fselection_cv.fit(x_train, y_train)\n",
        "    x_train = fselection_cv.transform(x_train)\n",
        "    clf_cv.fit(x_train, y_train)\n",
        "\n",
        "    # Test phase\n",
        "    x_test = fselection_cv.transform(x[test_index, :])\n",
        "    y_test = y[test_index]\n",
        "    y_pred = clf_cv.predict(x_test)\n",
        "    acc_i = accuracy_score(y_test, y_pred)\n",
        "    acc_cv.append(acc_i)\n",
        "\n",
        "  acc = np.average(acc_cv)\n",
        "  acc_nfeat.append(acc)\n",
        "  print('ACC:', acc)\n",
        "\n",
        "opt_index = np.argmax(acc_nfeat)\n",
        "opt_features = n_feats[opt_index]\n",
        "print(\"Optimal number of features: \", opt_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTAyrw3cuVm8",
        "outputId": "459ba8c5-56a7-4971-c48e-32a82a9991ab"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- Optimal selection of number of features -----\n",
            "---- n features = 1\n",
            "ACC: 0.8338914738332738\n",
            "---- n features = 2\n",
            "ACC: 0.8338914738332738\n",
            "---- n features = 3\n",
            "ACC: 0.8338914738332738\n",
            "---- n features = 4\n",
            "ACC: 0.8389054014098754\n",
            "---- n features = 5\n",
            "ACC: 0.8444826566657848\n",
            "---- n features = 6\n",
            "ACC: 0.8606526509080158\n",
            "---- n features = 7\n",
            "ACC: 0.8612081978182724\n",
            "---- n features = 8\n",
            "ACC: 0.8656759154074789\n",
            "---- n features = 9\n",
            "ACC: 0.8695662999330853\n",
            "---- n features = 10\n",
            "ACC: 0.8768133082273852\n",
            "---- n features = 11\n",
            "ACC: 0.8796143850858218\n",
            "---- n features = 12\n",
            "ACC: 0.8796050481629605\n",
            "---- n features = 13\n",
            "ACC: 0.8868489441496397\n",
            "Optimal number of features:  13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find optimal number of features using cross-validation\n",
        "################################################################################\n",
        "print(\"----- Optimal selection of number of features -----\")\n",
        "n_feats = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "acc_nfeat = []\n",
        "for n_feat in n_feats:\n",
        "  print('---- n features =', n_feat)\n",
        "  acc_cv = []\n",
        "  kf = StratifiedKFold(n_splits=5, shuffle = True)\n",
        "  for train_index, test_index in kf.split(x, y):\n",
        "    # Training phase\n",
        "    x_train = x[train_index, :]\n",
        "    y_train = y[train_index]\n",
        "    clf_cv = SVC(kernel = 'linear')\n",
        "    fselection_cv = SequentialFeatureSelector(clf_cv, n_features_to_select=n_feat)\n",
        "    fselection_cv.fit(x_train, y_train)\n",
        "    x_train = fselection_cv.transform(x_train)\n",
        "    clf_cv.fit(x_train, y_train)\n",
        "    # Test phase\n",
        "    x_test = fselection_cv.transform(x[test_index, :])\n",
        "    y_test = y[test_index]\n",
        "    y_pred = clf_cv.predict(x_test)\n",
        "    acc_i = accuracy_score(y_test, y_pred)\n",
        "    acc_cv.append(acc_i)\n",
        "\n",
        "  acc = np.average(acc_cv)\n",
        "  acc_nfeat.append(acc)\n",
        "  print('ACC:', acc)\n",
        "opt_index = np.argmax(acc_nfeat)\n",
        "opt_features = n_feats[opt_index]\n",
        "print(\"Optimal number of features: \", opt_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLDumsjCwGhg",
        "outputId": "bfc04cc7-6fa0-441e-9641-7c4f2d666553"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- Optimal selection of number of features -----\n",
            "---- n features = 1\n",
            "ACC: 0.8338914738332738\n",
            "---- n features = 2\n",
            "ACC: 0.8338914738332738\n",
            "---- n features = 3\n",
            "ACC: 0.8338914738332738\n",
            "---- n features = 4\n",
            "ACC: 0.8338914738332738\n",
            "---- n features = 5\n",
            "ACC: 0.8338914738332738\n",
            "---- n features = 6\n",
            "ACC: 0.8338914738332738\n",
            "---- n features = 7\n",
            "ACC: 0.8338914738332738\n",
            "---- n features = 8\n",
            "ACC: 0.8338914738332738\n",
            "---- n features = 9\n",
            "ACC: 0.8338914738332738\n",
            "Optimal number of features:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find optimal number of features using cross-validation\n",
        "################################################################################\n",
        "print(\"----- Optimal selection of number of features -----\")\n",
        "n_feats = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
        "acc_nfeat = []\n",
        "for n_feat in n_feats:\n",
        "  print('---- n features =', n_feat)\n",
        "  acc_cv = []\n",
        "  kf = StratifiedKFold(n_splits=5, shuffle = True)\n",
        "  for train_index, test_index in kf.split(x, y):\n",
        "    # Training phase\n",
        "    x_train = x[train_index, :]\n",
        "    y_train = y[train_index]\n",
        "    clf_cv = SVC(kernel = 'linear')\n",
        "    fselection_cv = RFE(clf_cv, n_features_to_select=n_feat)\n",
        "    fselection_cv.fit(x_train, y_train)\n",
        "    x_train = fselection_cv.transform(x_train)\n",
        "    clf_cv.fit(x_train, y_train)\n",
        "\n",
        "    # Test phase\n",
        "    x_test = fselection_cv.transform(x[test_index, :])\n",
        "    y_test = y[test_index]\n",
        "    y_pred = clf_cv.predict(x_test)\n",
        "    acc_i = accuracy_score(y_test, y_pred)\n",
        "    acc_cv.append(acc_i)\n",
        "\n",
        "  acc = np.average(acc_cv)\n",
        "  acc_nfeat.append(acc)\n",
        "  print('ACC:', acc)\n",
        "opt_index = np.argmax(acc_nfeat)\n",
        "opt_features = n_feats[opt_index]\n",
        "print(\"Optimal number of features: \", opt_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YHJ8iW55f8P",
        "outputId": "761ce27f-4212-47a2-e7f3-6293b10fd99a"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- Optimal selection of number of features -----\n",
            "---- n features = 1\n",
            "ACC: 0.8338914738332738\n",
            "---- n features = 2\n",
            "ACC: 0.8355627830254744\n",
            "---- n features = 3\n",
            "ACC: 0.8623161793311651\n",
            "---- n features = 4\n",
            "ACC: 0.8623255162540266\n",
            "---- n features = 5\n",
            "ACC: 0.8757037705606823\n",
            "---- n features = 6\n",
            "ACC: 0.8756913213302002\n",
            "---- n features = 7\n",
            "ACC: 0.8795941550862887\n",
            "---- n features = 8\n",
            "ACC: 0.8918706524952926\n",
            "---- n features = 9\n",
            "ACC: 0.8907408848290566\n",
            "---- n features = 10\n",
            "ACC: 0.8896422402390252\n",
            "---- n features = 11\n",
            "ACC: 0.893527956303201\n",
            "---- n features = 12\n",
            "ACC: 0.892981746315806\n",
            "---- n features = 13\n",
            "ACC: 0.8873858172141734\n",
            "Optimal number of features:  11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Escoge alguna de las técnicas de selección de características que probaste con anteioridad, y con el número óptimo de características encontrado, prepara tu modelo para producción haciendo lo siguiente:\n",
        "Aplica el método de selección de características con todos los datos.\n",
        "\n",
        "Ajusta el modelo con las características encontradas."
      ],
      "metadata": {
        "id": "JQ81T25BTxtF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter"
      ],
      "metadata": {
        "id": "NAMAKQdNVHmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find optimal number of features using cross-validation\n",
        "################################################################################\n",
        "print(\"----- Optimal selection of number of features -----\")\n",
        "n_feats = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
        "acc_nfeat = []\n",
        "for n_feat in n_feats:\n",
        "  print('---- n features =', n_feat)\n",
        "  acc_cv = []\n",
        "  kf = StratifiedKFold(n_splits=5, shuffle = True)\n",
        "  for train_index, test_index in kf.split(x, y):\n",
        "    # Training phase\n",
        "    x_train = x[train_index, :]\n",
        "    y_train = y[train_index]\n",
        "    clf_cv = SVC(kernel = 'linear')\n",
        "    fselection_cv = SelectKBest(f_classif, k = n_feat)\n",
        "    fselection_cv.fit(x_train, y_train)\n",
        "    x_train = fselection_cv.transform(x_train)\n",
        "    clf_cv.fit(x_train, y_train)\n",
        "\n",
        "    # Test phase\n",
        "    x_test = fselection_cv.transform(x[test_index, :])\n",
        "    y_test = y[test_index]\n",
        "    y_pred = clf_cv.predict(x_test)\n",
        "    acc_i = accuracy_score(y_test, y_pred)\n",
        "    acc_cv.append(acc_i)\n",
        "\n",
        "  acc = np.average(acc_cv)\n",
        "  acc_nfeat.append(acc)\n",
        "  print('ACC:', acc)\n",
        "\n",
        "opt_index = np.argmax(acc_nfeat)\n",
        "opt_features = n_feats[opt_index]\n",
        "print(\"Optimal number of features: \", opt_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kug1CPdnVIkZ",
        "outputId": "167470df-87e5-41e8-cb25-8a697477a773"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- Optimal selection of number of features -----\n",
            "---- n features = 1\n",
            "ACC: 0.8338914738332738\n",
            "---- n features = 2\n",
            "ACC: 0.8338914738332738\n",
            "---- n features = 3\n",
            "ACC: 0.8338914738332738\n",
            "---- n features = 4\n",
            "ACC: 0.8378020883584135\n",
            "---- n features = 5\n",
            "ACC: 0.8455999751015391\n",
            "---- n features = 6\n",
            "ACC: 0.8600893232287079\n",
            "---- n features = 7\n",
            "ACC: 0.8600908793825182\n",
            "---- n features = 8\n",
            "ACC: 0.8612019732030314\n",
            "---- n features = 9\n",
            "ACC: 0.8756944336378207\n",
            "---- n features = 10\n",
            "ACC: 0.8779150651250369\n",
            "---- n features = 11\n",
            "ACC: 0.8795925989324784\n",
            "---- n features = 12\n",
            "ACC: 0.881835016573038\n",
            "---- n features = 13\n",
            "ACC: 0.8874247210594295\n",
            "Optimal number of features:  13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit model with optimal number of features\n",
        "clf = SVC(kernel = 'linear')\n",
        "fselection = SelectKBest(f_classif, k = opt_features)\n",
        "fselection.fit(x, y)\n",
        "print(\"Selected features: \", fselection.get_feature_names_out())\n",
        "x_transformed = fselection.transform(x)\n",
        "clf.fit(x_transformed, y)\n",
        "y_pred = clf.predict(x_transformed)\n",
        "print(classification_report(y, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMZkjWQ7TclR",
        "outputId": "4349bdd6-8ed8-4cfb-bcbb-9ae2f9f4c9f3"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected features:  ['x11' 'x12' 'x16' 'x17' 'x18' 'x19' 'x20' 'x21' 'x27' 'x28' 'x29' 'x64'\n",
            " 'x65']\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.73      0.47      0.57       298\n",
            "         2.0       0.90      0.96      0.93      1496\n",
            "\n",
            "    accuracy                           0.88      1794\n",
            "   macro avg       0.81      0.72      0.75      1794\n",
            "weighted avg       0.87      0.88      0.87      1794\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Contesta las siguientes preguntas:\n",
        "\n",
        "**¿Qué pasa si no se considera el problema de tener datos desbalanceados para este caso? ¿Por qué?**\n",
        "\n",
        "Si no se considera ese caso, el modelo prodria optar por predecir la clase mayoritaria ya que tendria mas posibilidades de estar correcto en vez de realizar un correcto analisis.\n",
        "\n",
        "**De todos los clasificadores, ¿cuál o cuales consideras que son adecuados para los datos? ¿Qué propiedades tienen dichos modelos que los hacen apropiados para los datos? Argumenta tu respuesta.**\n",
        "\n",
        "Considero que el metodo de clasificación lineal es el mas adecuado para los datos debido que en la mayoria de los casos, el puntaje f1 es mayor en ambas clases comparandolo con los demas metodos\n",
        "\n",
        "**¿Es posibles reducir la dimensionalidad del problema sin perder rendimiento en el modelo? ¿Por qué?**\n",
        "\n",
        "En este caso no es posible reducir la dimensionalidad del problema debido a que las pruebas nos muestran que al intentar ajustar el modelo con ciertas caracteristicas se pierde rendimiento significante en el caso de la clase 1.\n",
        "\n",
        "**¿Qué método de selección de características consideras el más adecuado para este caso? ¿Por qué?**\n",
        "\n",
        "El metodo mas adecuado es Filter debido a que nos arroja el mejor resultado (y sobretodo en mucho menor tiempo)\n",
        "\n",
        "**Si quisieras mejorar el rendimiento de tus modelos, ¿qué más se podría hacer?**\n",
        "\n",
        "Se podria ajustar los hiperparametros o incluso probar diferentes algoritmos de clasificación para buscar uno que se adapte mejor a estos datos\n"
      ],
      "metadata": {
        "id": "hCpruUzGVrR1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problema 2"
      ],
      "metadata": {
        "id": "lKII-RXAfR4G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Determina si es necesario balancear los datos. En caso de que sea afirmativo, en todo este ejercicio tendrás que utilizar alguna estrategia para mitigar el problema de tener una muestra desbalanceada."
      ],
      "metadata": {
        "id": "ky6XI4IdgW8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = np.loadtxt(\"/content/drive/MyDrive/Inteligencia Artificial/M_1.txt\")"
      ],
      "metadata": {
        "id": "7lTeo-lTVp-7"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = df2[:,2:]"
      ],
      "metadata": {
        "id": "iFxJBy_whSlF"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df2[:,0]"
      ],
      "metadata": {
        "id": "cwpzWcs2hgqd"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kf = StratifiedKFold(n_splits=5, shuffle = True)\n",
        "clf = SVC(kernel = 'linear')\n",
        "cv_y_test = []\n",
        "cv_y_pred = []\n",
        "for train_index, test_index in kf.split(x, y):\n",
        "  # Training phase\n",
        "  x_train = x[train_index, :]\n",
        "  y_train = y[train_index]\n",
        "  clf.fit(x_train, y_train)\n",
        "\n",
        "  # Test phase\n",
        "  x_test = x[test_index, :]\n",
        "  y_test = y[test_index]\n",
        "  y_pred = clf.predict(x_test)\n",
        "\n",
        "  cv_y_test.append(y_test)\n",
        "  cv_y_pred.append(y_pred)\n",
        "\n",
        "print(classification_report(np.concatenate(cv_y_test), np.concatenate(cv_y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6du6Glfh6ZJ",
        "outputId": "161d213e-c6d3-4a4a-8f2d-aa2eeb4debb5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.99      0.99      0.99        90\n",
            "         2.0       0.93      0.97      0.95        90\n",
            "         3.0       0.97      0.93      0.95        90\n",
            "         4.0       1.00      0.99      0.99        90\n",
            "         5.0       0.99      0.98      0.98        90\n",
            "         6.0       0.90      0.90      0.90        90\n",
            "         7.0       0.99      1.00      0.99        90\n",
            "\n",
            "    accuracy                           0.97       630\n",
            "   macro avg       0.97      0.97      0.97       630\n",
            "weighted avg       0.97      0.97      0.97       630\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"----- Subsamplig -----\")\n",
        "clf = SVC(kernel = 'linear')\n",
        "kf = StratifiedKFold(n_splits=5, shuffle = True)\n",
        "cv_y_test = []\n",
        "cv_y_pred = []\n",
        "for train_index, test_index in kf.split(x, y):\n",
        "  # Training phase\n",
        "  x_train = x[train_index, :]\n",
        "  y_train = y[train_index]\n",
        "  x1 = x_train[y_train==1, :]\n",
        "  y1 = y_train[y_train==1]\n",
        "  n1 = len(y1)\n",
        "  x2 = x_train[y_train==2, :]\n",
        "  y2 = y_train[y_train==2]\n",
        "  n2 = len(y2)\n",
        "  ind = random.sample([i for i in range(n2)], n1)\n",
        "  x_sub = np.concatenate((x1, x2[ind,:]), axis=0)\n",
        "  y_sub = np.concatenate((y1, y2[ind]), axis=0)\n",
        "  clf.fit(x_sub, y_sub)\n",
        "  # Test phase\n",
        "  x_test = x[test_index, :]\n",
        "  y_test = y[test_index]\n",
        "  y_pred = clf.predict(x_test)\n",
        "  cv_y_test.append(y_test)\n",
        "  cv_y_pred.append(y_pred)\n",
        "print(classification_report(np.concatenate(cv_y_test), np.concatenate(cv_y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUHsUZFem8MX",
        "outputId": "88c49848-1bfb-49e4-ec95-27177929375e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- Subsamplig -----\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.49      1.00      0.66        90\n",
            "         2.0       0.20      1.00      0.33        90\n",
            "         3.0       0.00      0.00      0.00        90\n",
            "         4.0       0.00      0.00      0.00        90\n",
            "         5.0       0.00      0.00      0.00        90\n",
            "         6.0       0.00      0.00      0.00        90\n",
            "         7.0       0.00      0.00      0.00        90\n",
            "\n",
            "    accuracy                           0.29       630\n",
            "   macro avg       0.10      0.29      0.14       630\n",
            "weighted avg       0.10      0.29      0.14       630\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"----- Upsampling -----\")\n",
        "clf = SVC(kernel = 'linear')\n",
        "kf = StratifiedKFold(n_splits=5, shuffle = True)\n",
        "cv_y_test = []\n",
        "cv_y_pred = []\n",
        "\n",
        "for train_index, test_index in kf.split(x, y):\n",
        "  # Training phase\n",
        "  x_train = x[train_index, :]\n",
        "  y_train = y[train_index]\n",
        "\n",
        "  x1 = x_train[y_train==1, :]\n",
        "  y1 = y_train[y_train==1]\n",
        "  n1 = len(y1)\n",
        "\n",
        "  x2 = x_train[y_train==2, :]\n",
        "  y2 = y_train[y_train==2]\n",
        "  n2 = len(y2)\n",
        "\n",
        "  ind = random.choices([i for i in range(n1)], k = n2)\n",
        "  x_sub = np.concatenate((x1[ind,:], x2), axis=0)\n",
        "  y_sub = np.concatenate((y1[ind], y2), axis=0)\n",
        "\n",
        "  clf.fit(x_sub, y_sub)\n",
        "  # Test phase\n",
        "  x_test = x[test_index, :]\n",
        "  y_test = y[test_index]\n",
        "  y_pred = clf.predict(x_test)\n",
        "  cv_y_test.append(y_test)\n",
        "  cv_y_pred.append(y_pred)\n",
        "print(classification_report(np.concatenate(cv_y_test), np.concatenate(cv_y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgfqkiAdnNhi",
        "outputId": "96a9d775-ff7a-4147-beb6-256406e7ac72"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- Upsampling -----\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.50      1.00      0.66        90\n",
            "         2.0       0.20      1.00      0.33        90\n",
            "         3.0       0.00      0.00      0.00        90\n",
            "         4.0       0.00      0.00      0.00        90\n",
            "         5.0       0.00      0.00      0.00        90\n",
            "         6.0       0.00      0.00      0.00        90\n",
            "         7.0       0.00      0.00      0.00        90\n",
            "\n",
            "    accuracy                           0.29       630\n",
            "   macro avg       0.10      0.29      0.14       630\n",
            "weighted avg       0.10      0.29      0.14       630\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"----- Weighted loss function -----\")\n",
        "clf = SVC(kernel = 'linear', class_weight='balanced')\n",
        "kf = StratifiedKFold(n_splits=5, shuffle = True)\n",
        "cv_y_test = []\n",
        "cv_y_pred = []\n",
        "for train_index, test_index in kf.split(x, y):\n",
        "  # Training phase\n",
        "  x_train = x[train_index, :]\n",
        "  y_train = y[train_index]\n",
        "  clf.fit(x_train, y_train)\n",
        "  # Test phase\n",
        "  x_test = x[test_index, :]\n",
        "  y_test = y[test_index]\n",
        "  y_pred = clf.predict(x_test)\n",
        "  cv_y_test.append(y_test)\n",
        "  cv_y_pred.append(y_pred)\n",
        "print(classification_report(np.concatenate(cv_y_test), np.concatenate(cv_y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-zNxrpPnqEp",
        "outputId": "76749bcb-307b-4da9-a891-1b6c0de2e54e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- Weighted loss function -----\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       1.00      0.97      0.98        90\n",
            "         2.0       0.94      0.99      0.96        90\n",
            "         3.0       0.99      0.94      0.97        90\n",
            "         4.0       1.00      0.99      0.99        90\n",
            "         5.0       0.97      0.99      0.98        90\n",
            "         6.0       0.96      0.96      0.96        90\n",
            "         7.0       0.99      1.00      0.99        90\n",
            "\n",
            "    accuracy                           0.98       630\n",
            "   macro avg       0.98      0.98      0.98       630\n",
            "weighted avg       0.98      0.98      0.98       630\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evalúa al menos 5 modelos de clasificación distintos utilizando validación cruzada, y determina cuál de ellos es el más efectivo."
      ],
      "metadata": {
        "id": "ZzO9GRH0m-ju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kf = StratifiedKFold(n_splits=5, shuffle = True)\n",
        "clf = SVC(kernel = 'linear')\n",
        "cv_y_test = []\n",
        "cv_y_pred = []\n",
        "for train_index, test_index in kf.split(x, y):\n",
        "  # Training phase\n",
        "  x_train = x[train_index, :]\n",
        "  y_train = y[train_index]\n",
        "  clf.fit(x_train, y_train)\n",
        "\n",
        "  # Test phase\n",
        "  x_test = x[test_index, :]\n",
        "  y_test = y[test_index]\n",
        "  y_pred = clf.predict(x_test)\n",
        "\n",
        "  cv_y_test.append(y_test)\n",
        "  cv_y_pred.append(y_pred)\n",
        "\n",
        "print(classification_report(np.concatenate(cv_y_test), np.concatenate(cv_y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wi5Onc3rCYdu",
        "outputId": "86a77953-c144-4421-b2f3-601ac5de4dc5"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       1.00      0.99      0.99        90\n",
            "         2.0       0.92      0.99      0.95        90\n",
            "         3.0       0.97      0.96      0.96        90\n",
            "         4.0       1.00      0.99      0.99        90\n",
            "         5.0       0.99      0.98      0.98        90\n",
            "         6.0       0.95      0.91      0.93        90\n",
            "         7.0       0.99      1.00      0.99        90\n",
            "\n",
            "    accuracy                           0.97       630\n",
            "   macro avg       0.97      0.97      0.97       630\n",
            "weighted avg       0.97      0.97      0.97       630\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('----- RBF-SVM -----')\n",
        "kf = StratifiedKFold(n_splits=5, shuffle = True)\n",
        "cv_y_test = []\n",
        "cv_y_pred = []\n",
        "for train_index, test_index in kf.split(x, y):\n",
        "  x_train = x[train_index, :]\n",
        "  y_train = y[train_index]\n",
        "  x_test = x[test_index, :]\n",
        "  y_test = y[test_index]\n",
        "  clf = SVC(kernel = 'rbf')\n",
        "  clf.fit(x_train, y_train)\n",
        "  y_pred = clf.predict(x_test)\n",
        "  cv_y_test.append(y_test)\n",
        "  cv_y_pred.append(y_pred)\n",
        "print(classification_report(np.concatenate(cv_y_test), np.concatenate(cv_y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0U0lYcPmkDS9",
        "outputId": "824b50ef-4702-48a9-cad0-a1c6cb87bb64"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- RBF-SVM -----\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.97      1.00      0.98        90\n",
            "         2.0       0.93      0.99      0.96        90\n",
            "         3.0       0.98      0.94      0.96        90\n",
            "         4.0       1.00      1.00      1.00        90\n",
            "         5.0       0.99      0.94      0.97        90\n",
            "         6.0       0.95      0.92      0.94        90\n",
            "         7.0       0.99      1.00      0.99        90\n",
            "\n",
            "    accuracy                           0.97       630\n",
            "   macro avg       0.97      0.97      0.97       630\n",
            "weighted avg       0.97      0.97      0.97       630\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('----- KNN -----')\n",
        "kf = StratifiedKFold(n_splits=5, shuffle = True)\n",
        "cv_y_test = []\n",
        "cv_y_pred = []\n",
        "for train_index, test_index in kf.split(x, y):\n",
        "  x_train = x[train_index, :]\n",
        "  y_train = y[train_index]\n",
        "  x_test = x[test_index, :]\n",
        "  y_test = y[test_index]\n",
        "  clf = KNeighborsClassifier(n_neighbors=3)\n",
        "  clf.fit(x_train, y_train)\n",
        "  y_pred = clf.predict(x_test)\n",
        "  cv_y_test.append(y_test)\n",
        "  cv_y_pred.append(y_pred)\n",
        "print(classification_report(np.concatenate(cv_y_test), np.concatenate(cv_y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb9I7Q0MkL_g",
        "outputId": "6793d8a5-9614-4aa5-abac-44a603ef929b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- KNN -----\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.97      0.99      0.98        90\n",
            "         2.0       0.88      0.99      0.93        90\n",
            "         3.0       0.95      0.91      0.93        90\n",
            "         4.0       1.00      1.00      1.00        90\n",
            "         5.0       1.00      0.93      0.97        90\n",
            "         6.0       0.93      0.89      0.91        90\n",
            "         7.0       0.99      1.00      0.99        90\n",
            "\n",
            "    accuracy                           0.96       630\n",
            "   macro avg       0.96      0.96      0.96       630\n",
            "weighted avg       0.96      0.96      0.96       630\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('----- Decision tree -----')\n",
        "kf = StratifiedKFold(n_splits=5, shuffle = True)\n",
        "cv_y_test = []\n",
        "cv_y_pred = []\n",
        "for train_index, test_index in kf.split(x, y):\n",
        "  x_train = x[train_index, :]\n",
        "  y_train = y[train_index]\n",
        "  x_test = x[test_index, :]\n",
        "  y_test = y[test_index]\n",
        "  clf = DecisionTreeClassifier()\n",
        "  clf.fit(x_train, y_train)\n",
        "  y_pred = clf.predict(x_test)\n",
        "  cv_y_test.append(y_test)\n",
        "  cv_y_pred.append(y_pred)\n",
        "print(classification_report(np.concatenate(cv_y_test), np.concatenate(cv_y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JsN02FskO8n",
        "outputId": "716bfd5a-3a9b-4a32-823f-db4131eb5c6b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- Decision tree -----\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.94      0.92      0.93        90\n",
            "         2.0       0.79      0.79      0.79        90\n",
            "         3.0       0.86      0.87      0.86        90\n",
            "         4.0       0.91      0.89      0.90        90\n",
            "         5.0       0.90      0.88      0.89        90\n",
            "         6.0       0.77      0.80      0.79        90\n",
            "         7.0       0.97      0.99      0.98        90\n",
            "\n",
            "    accuracy                           0.88       630\n",
            "   macro avg       0.88      0.88      0.88       630\n",
            "weighted avg       0.88      0.88      0.88       630\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('----- Linear Discriminant Analysis -----')\n",
        "kf = StratifiedKFold(n_splits=5, shuffle = True)\n",
        "cv_y_test = []\n",
        "cv_y_pred = []\n",
        "for train_index, test_index in kf.split(x, y):\n",
        "  x_train = x[train_index, :]\n",
        "  y_train = y[train_index]\n",
        "  x_test = x[test_index, :]\n",
        "  y_test = y[test_index]\n",
        "  clf = LinearDiscriminantAnalysis()\n",
        "  clf.fit(x_train, y_train)\n",
        "  y_pred = clf.predict(x_test)\n",
        "  cv_y_test.append(y_test)\n",
        "  cv_y_pred.append(y_pred)\n",
        "print(classification_report(np.concatenate(cv_y_test), np.concatenate(cv_y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXxKIccSkWpP",
        "outputId": "7c430ac6-fa44-436a-dbd8-75478a3d48af"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- Linear Discriminant Analysis -----\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.87      0.84      0.86        90\n",
            "         2.0       0.78      0.84      0.81        90\n",
            "         3.0       0.74      0.78      0.76        90\n",
            "         4.0       0.95      0.90      0.93        90\n",
            "         5.0       0.82      0.83      0.82        90\n",
            "         6.0       0.66      0.63      0.64        90\n",
            "         7.0       1.00      0.97      0.98        90\n",
            "\n",
            "    accuracy                           0.83       630\n",
            "   macro avg       0.83      0.83      0.83       630\n",
            "weighted avg       0.83      0.83      0.83       630\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Escoge al menos dos clasificadores que hayas evaluado en el paso anterior e identifica sus hiperparámetros. Lleva a cabo el proceso de validación cruzada anidada para evaluar los dos modelos con la selección óptima de hiperparámetros."
      ],
      "metadata": {
        "id": "bk-wfHm3TQGb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM"
      ],
      "metadata": {
        "id": "8MxGIaMSYgDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"----- SVM classifier - Regularization parameter -----\")\n",
        "cc = np.logspace(-3, 1, 100)\n",
        "acc = []\n",
        "for c in cc:\n",
        "  acc_cv = []\n",
        "  kf = StratifiedKFold(n_splits=5, shuffle = True)\n",
        "\n",
        "  for train_index, test_index in kf.split(x, y):\n",
        "    # Training phase\n",
        "    x_train = x[train_index, :]\n",
        "    y_train = y[train_index]\n",
        "    clf_cv = SVC(C=c, kernel = 'linear')\n",
        "    clf_cv.fit(x_train, y_train)\n",
        "\n",
        "    # Test phase\n",
        "    x_test = x[test_index, :]\n",
        "    y_test = y[test_index]\n",
        "    y_pred = clf_cv.predict(x_test)\n",
        "    acc_i = accuracy_score(y_test, y_pred)\n",
        "    acc_cv.append(acc_i)\n",
        "\n",
        "  acc_hyp = np.average(acc_cv)\n",
        "  acc.append(acc_hyp)\n",
        "opt_index = np.argmax(acc)\n",
        "opt_hyperparameter_linear = cc[opt_index]\n",
        "print(f\"Best parameter : C = {opt_hyperparameter_linear:.4f}\")\n",
        "print(f\"Accuracy = {acc[opt_index]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-8412YpU6-U",
        "outputId": "520ad96a-e0dc-4ac3-daca-3a8c6ec387c1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- SVM classifier - Regularization parameter -----\n",
            "Best parameter : C = 0.0112\n",
            "Accuracy = 0.9825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RB-SVM"
      ],
      "metadata": {
        "id": "OQK4oFYwfeFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"----- RB-SVM classifier - Smoothing parameter -----\")\n",
        "gg = np.logspace(-5, -1, 100)\n",
        "acc = []\n",
        "for g in gg:\n",
        "  acc_cv = []\n",
        "  kf = StratifiedKFold(n_splits=5, shuffle = True)\n",
        "  for train_index, test_index in kf.split(x, y):\n",
        "    # Training phase\n",
        "    x_train = x[train_index, :]\n",
        "    y_train = y[train_index]\n",
        "    clf_cv = SVC(kernel ='rbf', gamma = g)\n",
        "    clf_cv.fit(x_train, y_train)\n",
        "\n",
        "    # Test phase\n",
        "    x_test = x[test_index, :]\n",
        "    y_test = y[test_index]\n",
        "    y_pred = clf_cv.predict(x_test)\n",
        "    acc_i = accuracy_score(y_test, y_pred)\n",
        "    acc_cv.append(acc_i)\n",
        "\n",
        "  acc_hyp = np.average(acc_cv)\n",
        "  acc.append(acc_hyp)\n",
        "\n",
        "opt_index = np.argmax(acc)\n",
        "opt_hyperparameter_rb = gg[opt_index]\n",
        "print(f\"Best parameter : G = {opt_hyperparameter_rb:.4f}\")\n",
        "print(f\"Accuracy = {acc[opt_index]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUkDBWgZYIMQ",
        "outputId": "e99f7817-bd56-41c2-b2cb-9785a447049c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- RB-SVM classifier - Smoothing parameter -----\n",
            "Best parameter : G = 0.0003\n",
            "Accuracy = 0.9746\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Prepara tus modelos para producción haciendo lo siguiente:\n",
        "Opten los hiperparámetros óptimos utilizando todo el conjunto de datos con validación cruzada.\n",
        "\n",
        "Con los hiperparámetros óptimos, ajusta el modelo con todos los datos."
      ],
      "metadata": {
        "id": "C4KWfDomegWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = SVC(C=opt_hyperparameter_linear, kernel = 'linear')\n",
        "clf.fit(x, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "4cpRFeO3ekJ5",
        "outputId": "4f7b0d63-a965-4e91-f944-78bce290b328"
      },
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=0.0036783797718286343, kernel='linear')"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=0.0036783797718286343, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=0.0036783797718286343, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = SVC(C=opt_hyperparameter_rb, kernel = 'rbf')\n",
        "clf.fit(x, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "TwoTf3q7fmYt",
        "outputId": "21efa72e-832d-4092-845c-da74c05ac310"
      },
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=0.001047615752789665)"
            ],
            "text/html": [
              "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=0.001047615752789665)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=0.001047615752789665)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 265
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Contesta lo siguientes:\n",
        "\n",
        "**¿Observas un problema en cuanto al balanceo de las clases? ¿Por qué?**\n",
        "\n",
        "Si, en el metodo de subsampling y upsampling solo toma en cuenta las primeras dos clases y el resto las ignora por completo.\n",
        "\n",
        "**¿Qué modelo o modelos fueron efectivos para clasificar tus datos? ¿Observas algo especial sobre los modelos? Argumenta tu respuesta.**\n",
        "\n",
        "el modelo de SVM y RB-SVM fueron los modelos mas efectivos para estos datos. Algo curioso de los modelos es que tanto en estos dos modelos como en KNN se predice con un 1 de efectividad la clase 4.\n",
        "\n",
        "**¿Observas alguna mejora importante al optimizar hiperparámetros? ¿Es el resultado que esperabas? Argumenta tu respuesta.**\n",
        "\n",
        "Existe una leve mejora al optimizar los hiperparametros. Debido a que el modelo o modelos originales ya presentaban un buen resultado, realmente no esperaba que mejorasen mucho más.\n",
        "\n",
        "**¿Qué inconvenientes hay al encontrar hiperparámetros? ¿Por qué?**\n",
        "\n",
        "Encontrar los hiperparametros optimos puede suponer una mayor carga computacional y gasto de tiempo para que en algunos casos no haya una mejora significativa o incluso puedan llegar a empeorar el modelo al evaluarlo con los datos de prueba."
      ],
      "metadata": {
        "id": "W2LoKytYgs-v"
      }
    }
  ]
}